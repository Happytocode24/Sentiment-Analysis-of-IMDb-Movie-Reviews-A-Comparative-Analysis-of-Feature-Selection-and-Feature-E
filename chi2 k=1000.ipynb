{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"labeledTrainData.tsv\", sep=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words(\"english\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(raw_text,stopwords=stop):\n",
    "    remove_html_tags=BeautifulSoup(raw_text).get_text()\n",
    "    remove_char=re.sub(\"[^a-zA-Z]\",\" \",remove_html_tags)\n",
    "    lower_text=remove_char.lower().split()\n",
    "    remove_stop=[i for i in lower_text if not i in stopwords]\n",
    "    lemmatized_text=[wordnet_lemmatizer.lemmatize(word,'v') for word in remove_stop]\n",
    "    return \" \".join(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_review']=data['review'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuff go moment mj start listen music watch odd documentary watch wiz watch moonwalker maybe want get certain insight guy think really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember go see cinema originally release subtle message mj feel towards press also obvious message drug bad kay visually impressive course michael jackson unless remotely like mj anyway go hate find bore may call mj egotist consent make movie mj fan would say make fan true really nice actual feature film bite finally start minutes exclude smooth criminal sequence joe pesci convince psychopathic powerful drug lord want mj dead bad beyond mj overhear plan nah joe pesci character rant want people know supply drug etc dunno maybe hat mj music lot cool things like mj turn car robot whole speed demon sequence also director must patience saint come film kiddy bad sequence usually directors hate work one kid let alone whole bunch perform complex dance scene bottom line movie people like mj one level another think people stay away try give wholesome message ironically mj bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention give subject hmmm well know people different behind close doors know fact either extremely nice stupid guy one sickest liars hope latter'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Chi2 for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2,SelectKBest\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X=data['clean_review']\n",
    "y=data['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 62994)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf=TfidfVectorizer()\n",
    "X_sel=tf_idf.fit_transform(X)\n",
    "X_sel.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=SelectKBest(chi2,k=1000)\n",
    "X_vec=features.fit_transform(X_sel,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_vector, X_test_vector, Y_train, Y_test=train_test_split(X_vec,y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN K=3 with Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65      4105\n",
      "           1       0.65      0.70      0.67      4145\n",
      "\n",
      "    accuracy                           0.66      8250\n",
      "   macro avg       0.66      0.66      0.66      8250\n",
      "weighted avg       0.66      0.66      0.66      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_vector,Y_train)\n",
    "Y_pred=knn.predict(X_test_vector)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN K=7 with Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.65      0.67      4105\n",
      "           1       0.67      0.72      0.70      4145\n",
      "\n",
      "    accuracy                           0.68      8250\n",
      "   macro avg       0.68      0.68      0.68      8250\n",
      "weighted avg       0.68      0.68      0.68      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train_vector,Y_train)\n",
    "Y_pred=knn.predict(X_test_vector)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with k=10 with Chi2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.75      0.71      4105\n",
      "           1       0.72      0.62      0.67      4145\n",
      "\n",
      "    accuracy                           0.69      8250\n",
      "   macro avg       0.69      0.69      0.69      8250\n",
      "weighted avg       0.69      0.69      0.69      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train_vector,Y_train)\n",
    "Y_pred=knn.predict(X_test_vector)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      4105\n",
      "           1       0.88      0.89      0.88      4145\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "s=svm.SVC()\n",
    "s.fit(X_train_vector, Y_train)\n",
    "Y_pred=s.predict(X_test_vector)\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      4105\n",
      "           1       0.86      0.89      0.88      4145\n",
      "\n",
      "    accuracy                           0.87      8250\n",
      "   macro avg       0.87      0.87      0.87      8250\n",
      "weighted avg       0.87      0.87      0.87      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(penalty='l2')\n",
    "lr.fit(X_train_vector, Y_train)\n",
    "Y_pred=lr.predict(X_test_vector)\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.84      4105\n",
      "           1       0.84      0.83      0.84      4145\n",
      "\n",
      "    accuracy                           0.84      8250\n",
      "   macro avg       0.84      0.84      0.84      8250\n",
      "weighted avg       0.84      0.84      0.84      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train_vector, Y_train)\n",
    "Y_pred=rf.predict(X_test_vector)\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      4105\n",
      "           1       0.87      0.87      0.87      4145\n",
      "\n",
      "    accuracy                           0.87      8250\n",
      "   macro avg       0.87      0.87      0.87      8250\n",
      "weighted avg       0.87      0.87      0.87      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb=MultinomialNB()\n",
    "nb.fit(X_train_vector, Y_train)\n",
    "Y_pred=nb.predict(X_test_vector)\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.72      4105\n",
      "           1       0.72      0.73      0.72      4145\n",
      "\n",
      "    accuracy                           0.72      8250\n",
      "   macro avg       0.72      0.72      0.72      8250\n",
      "weighted avg       0.72      0.72      0.72      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dt=tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train_vector, Y_train)\n",
    "Y_pred=dt.predict(X_test_vector)\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gahina\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:08:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.75      4105\n",
      "           1       0.74      0.84      0.79      4145\n",
      "\n",
      "    accuracy                           0.77      8250\n",
      "   macro avg       0.78      0.77      0.77      8250\n",
      "weighted avg       0.78      0.77      0.77      8250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xb=XGBClassifier(max_depth=5, alpha=10, n_estimators=10)\n",
    "xb.fit(X_train_vector, Y_train)\n",
    "Y_pred=xb.predict(X_test_vector)\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
