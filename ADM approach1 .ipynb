{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"labeledTrainData.tsv\", sep=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words(\"english\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(raw_text,stopwords=stop):\n",
    "    remove_html_tags=BeautifulSoup(raw_text).get_text()\n",
    "    remove_char=re.sub(\"[^a-zA-Z]\",\" \",remove_html_tags)\n",
    "    lower_text=remove_char.lower().split()\n",
    "    remove_stop=[i for i in lower_text if not i in stopwords]\n",
    "    lemmatized_text=[wordnet_lemmatizer.lemmatize(word,'v') for word in remove_stop]\n",
    "    return \" \".join(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_review']=data['review'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuff go moment mj start listen music watch odd documentary watch wiz watch moonwalker maybe want get certain insight guy think really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember go see cinema originally release subtle message mj feel towards press also obvious message drug bad kay visually impressive course michael jackson unless remotely like mj anyway go hate find bore may call mj egotist consent make movie mj fan would say make fan true really nice actual feature film bite finally start minutes exclude smooth criminal sequence joe pesci convince psychopathic powerful drug lord want mj dead bad beyond mj overhear plan nah joe pesci character rant want people know supply drug etc dunno maybe hat mj music lot cool things like mj turn car robot whole speed demon sequence also director must patience saint come film kiddy bad sequence usually directors hate work one kid let alone whole bunch perform complex dance scene bottom line movie people like mj one level another think people stay away try give wholesome message ironically mj bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention give subject hmmm well know people different behind close doors know fact either extremely nice stupid guy one sickest liars hope latter'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16750, 1000), (8250, 1000))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=data['clean_review']\n",
    "y=data['sentiment']\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "vector=CountVectorizer(max_features=1000)\n",
    "vector.fit(X_train.tolist())\n",
    "X_train_vector=vector.transform(X_train.tolist()).toarray()\n",
    "X_test_vector=vector.transform(X_test.tolist()).toarray()\n",
    "X_train_vector.shape, X_test_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN k=3 without IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61      4105\n",
      "           1       0.62      0.66      0.64      4145\n",
      "\n",
      "    accuracy                           0.63      8250\n",
      "   macro avg       0.63      0.63      0.63      8250\n",
      "weighted avg       0.63      0.63      0.63      8250\n",
      "\n",
      "12.58481764793396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "import time\n",
    "now=time.time()\n",
    "knn.fit(X_train_vector,Y_train)\n",
    "Y_pred=knn.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN k=7 without IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66      4105\n",
      "           1       0.66      0.65      0.66      4145\n",
      "\n",
      "    accuracy                           0.66      8250\n",
      "   macro avg       0.66      0.66      0.66      8250\n",
      "weighted avg       0.66      0.66      0.66      8250\n",
      "\n",
      "25.88218402862549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=10)\n",
    "import time\n",
    "now=time.time()\n",
    "knn.fit(X_train_vector,Y_train)\n",
    "Y_pred=knn.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Information gain for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X=data['clean_review']\n",
    "y=data['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(max_df=0.95, min_df=2, max_features=10000, stop_words='english')\n",
    "X_vec=cv.fit_transform(X)\n",
    "res=dict(zip(cv.get_feature_names(),mutual_info_classif(X_vec, y, discrete_features=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "6044\n"
     ]
    }
   ],
   "source": [
    "print(len(res))\n",
    "count=0\n",
    "for k,v in res.items():\n",
    "    if res[k]>=0.0001:\n",
    "        count+=1\n",
    "        #print(k)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(text,res=res):\n",
    "    l=[]\n",
    "    d=text.split()\n",
    "    for word in d:\n",
    "        #print(word)\n",
    "        if word in res.keys() and res[word]>=0.0001:\n",
    "            l.append(word)\n",
    "    return \" \".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sel_feature']=data['clean_review'].apply(select_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        stuff moment mj start listen music watch docum...\n",
       "1        classic war worlds timothy entertain film obvi...\n",
       "2        film start manager nicholas welcome robert car...\n",
       "3        assume film greatest film opera read care oper...\n",
       "4        superbly trashy unpretentious exploitation pre...\n",
       "                               ...                        \n",
       "24995    like imdb review film review think happen dres...\n",
       "24996    believe make film completely unnecessary film ...\n",
       "24997    guy loser girls need build pick stronger succe...\n",
       "24998    minute documentary make early poorest opinion ...\n",
       "24999    saw movie child break heart story end grow gre...\n",
       "Name: sel_feature, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sel_feature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF_IDF for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16750, 6044)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=data['sel_feature']\n",
    "y=data['sentiment']\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,y, test_size=0.33, random_state=42)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf=TfidfVectorizer()\n",
    "X_train_vector=tf_idf.fit_transform(X_train)\n",
    "X_train_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8250, 6044)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vector=tf_idf.transform(X_test)\n",
    "X_test_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN K=3 with IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75      4105\n",
      "           1       0.74      0.81      0.77      4145\n",
      "\n",
      "    accuracy                           0.76      8250\n",
      "   macro avg       0.76      0.76      0.76      8250\n",
      "weighted avg       0.76      0.76      0.76      8250\n",
      "\n",
      "11.142491817474365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "now=time.time()\n",
    "knn.fit(X_train_vector,Y_train)\n",
    "Y_pred=knn.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN K=7 with IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      4105\n",
      "           1       0.76      0.83      0.79      4145\n",
      "\n",
      "    accuracy                           0.78      8250\n",
      "   macro avg       0.78      0.78      0.78      8250\n",
      "weighted avg       0.78      0.78      0.78      8250\n",
      "\n",
      "11.535353422164917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=7)\n",
    "now=time.time()\n",
    "knn.fit(X_train_vector,Y_train)\n",
    "Y_pred=knn.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN with k=10 with IG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      4105\n",
      "           1       0.79      0.78      0.79      4145\n",
      "\n",
      "    accuracy                           0.79      8250\n",
      "   macro avg       0.79      0.79      0.79      8250\n",
      "weighted avg       0.79      0.79      0.79      8250\n",
      "\n",
      "11.23954701423645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=10)\n",
    "now=time.time()\n",
    "knn.fit(X_train_vector,Y_train)\n",
    "Y_pred=knn.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      4105\n",
      "           1       0.88      0.91      0.89      4145\n",
      "\n",
      "    accuracy                           0.89      8250\n",
      "   macro avg       0.89      0.89      0.89      8250\n",
      "weighted avg       0.89      0.89      0.89      8250\n",
      "\n",
      "462.7750928401947\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "s=svm.SVC()\n",
    "now=time.time()\n",
    "s.fit(X_train_vector, Y_train)\n",
    "Y_pred=s.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      4105\n",
      "           1       0.87      0.90      0.89      4145\n",
      "\n",
      "    accuracy                           0.88      8250\n",
      "   macro avg       0.88      0.88      0.88      8250\n",
      "weighted avg       0.88      0.88      0.88      8250\n",
      "\n",
      "0.4799950122833252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(penalty='l2')\n",
    "now=time.time()\n",
    "lr.fit(X_train_vector, Y_train)\n",
    "Y_pred=lr.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      4105\n",
      "           1       0.85      0.84      0.85      4145\n",
      "\n",
      "    accuracy                           0.85      8250\n",
      "   macro avg       0.85      0.85      0.85      8250\n",
      "weighted avg       0.85      0.85      0.85      8250\n",
      "\n",
      "31.4950749874115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "now=time.time()\n",
    "rf.fit(X_train_vector, Y_train)\n",
    "Y_pred=rf.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4105\n",
      "           1       0.87      0.86      0.86      4145\n",
      "\n",
      "    accuracy                           0.86      8250\n",
      "   macro avg       0.86      0.86      0.86      8250\n",
      "weighted avg       0.86      0.86      0.86      8250\n",
      "\n",
      "0.022989511489868164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb=MultinomialNB()\n",
    "now=time.time()\n",
    "nb.fit(X_train_vector, Y_train)\n",
    "Y_pred=nb.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72      4105\n",
      "           1       0.72      0.71      0.72      4145\n",
      "\n",
      "    accuracy                           0.72      8250\n",
      "   macro avg       0.72      0.72      0.72      8250\n",
      "weighted avg       0.72      0.72      0.72      8250\n",
      "\n",
      "15.415213584899902\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "dt=tree.DecisionTreeClassifier()\n",
    "now=time.time()\n",
    "dt.fit(X_train_vector, Y_train)\n",
    "Y_pred=dt.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:38:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.68      0.75      4105\n",
      "           1       0.73      0.86      0.79      4145\n",
      "\n",
      "    accuracy                           0.77      8250\n",
      "   macro avg       0.78      0.77      0.77      8250\n",
      "weighted avg       0.78      0.77      0.77      8250\n",
      "\n",
      "3.2723329067230225\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xb=XGBClassifier(max_depth=5, alpha=10, n_estimators=10)\n",
    "now=time.time()\n",
    "xb.fit(X_train_vector, Y_train)\n",
    "Y_pred=xb.predict(X_test_vector)\n",
    "fin=time.time()-now\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "print(fin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
